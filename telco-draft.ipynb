{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "premier-milan",
   "metadata": {},
   "source": [
    "# Telco Data: Customer Churn Supposition\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "going-assembly",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0f1c80c3",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'username' from 'env' (/Users/racheldownen/codeup-data-science/classification-exercises/env.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Input \u001b[0;32mIn [4]\u001b[0m, in \u001b[0;36m<cell line: 16>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     12\u001b[0m warnings\u001b[38;5;241m.\u001b[39mfilterwarnings(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mmatplotlib\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpyplot\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mplt\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01macquire\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mac\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mprepare\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpr\u001b[39;00m\n",
      "File \u001b[0;32m~/codeup-data-science/classification-exercises/acquire.py:4\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m import numpy as np\n\u001b[1;32m      3\u001b[0m import os\n\u001b[0;32m----> 4\u001b[0m from env import host, username, password\n\u001b[1;32m      5\u001b[0m \n\u001b[1;32m      6\u001b[0m def get_db_url(db, user+username, host=host, password=password):\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'username' from 'env' (/Users/racheldownen/codeup-data-science/classification-exercises/env.py)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "# acquire\n",
    "import env\n",
    "from pydataset import data\n",
    "import seaborn as sns\n",
    "\n",
    "# turn off pink warning boxes\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import acquire as ac\n",
    "import prepare as pr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07964771",
   "metadata": {},
   "outputs": [],
   "source": [
    "# to see all columns in wide datasets\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-glory",
   "metadata": {},
   "source": [
    "## Acquire\n",
    "\n",
    "* I retrieved my data from the Codeup databases using my acquire.py file\n",
    "* I retrieved my data on Tuesday, October 25, 2022\n",
    "* What is the size of your data? (columns and rows)\n",
    "* What does each observation represent?\n",
    "* What does each column represent?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba64e83",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco = ac.get_telco_data()\n",
    "telco.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "222a4a1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57a79487",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53c283e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66425a7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco.isnull()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc46c53",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2012f94b",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco.shape"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c9d81dff",
   "metadata": {},
   "source": [
    "1. Does having tech support affect customer churn rates?\n",
    "2. Does payment type affect customers churn rates?\n",
    "3. Does being a senior citizen affect customers churn rates?\n",
    "4. Does contract type affect customers churn rates?\n",
    "5. Does paperless billing affect customer churn rates?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198705b9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "raw",
   "id": "b3410880",
   "metadata": {},
   "source": [
    "Clean the data:\n",
    "\n",
    "missing values: drop columns with too many missing values, drop rows with too many missing values, fill with zero where it makes sense, and then make note of any columns you want to impute missing values in (you will need to do that on split data).\n",
    "outlier: an observation point that is distant from other observations https://www.theanalysisfactor.com/outliers-to-drop-or-not-to-drop/\n",
    "outliers: ignore, drop rows, snap to a selected max/min value, create bins (cut, qcut)\n",
    "data errors: drop the rows/observations with the errors, correct them to what it was intended\n",
    "address text normalization issues...e.g. deck 'C' 'c'. (correct and standardize the text)\n",
    "tidy data: getting your data in the shape it needs to be for modeling and exploring. every row should be an observation and every column should be a feature/attribute/variable. You want 1 observation per row, and 1 row per observation. If you want to predict a customer churn, each row should be a customer and each customer should be on only 1 row. (address duplicates, aggregate, melt, reshape, ...)\n",
    "creating new variables out of existing variables (e.g. z = x - y)\n",
    "rename columns\n",
    "datatypes: need numeric data to be able to feed into model (dummy vars, factor vars, manual encoding)\n",
    "scale numeric data: so that continuous variables have the same weight, are on the same units, if algorithm will be used that will be affected by the differing weights, or if data needs to be scaled to a gaussian/normal distribution for statistical testing. (linear scalers and non-linear scalers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf08c78b",
   "metadata": {},
   "outputs": [],
   "source": [
    "No missing values, so no need to drop rows or fill in zereos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "impossible-bible",
   "metadata": {},
   "source": [
    "## Prepare\n",
    "\n",
    "* List steps taken to clean your data here\n",
    "* In particular call out how you handle null values and outliers in detail\n",
    "* You must do this even if you do not do anything or do not encounter any\n",
    "* Any time there is potential to make changes to the data you must be upfront about the changes you make or do not make"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "flexible-irrigation",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import your prepare function and use it to clean your data here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1160775",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = pr.prep_telco_data(telco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "015d6b80",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a09cb6b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "immediate-mirror",
   "metadata": {},
   "source": [
    "## Explore\n",
    "\n",
    "* Here you will explore your data then highlight 4 questions that you asked of the data and how those questions influenced your analysis\n",
    "* Remember to split your data before exploring how different variables relate to one another\n",
    "* Each question should be stated directly \n",
    "* Each question should be supported by a visualization\n",
    "* Each question should be answered in natural language\n",
    "* Two questions must be supported by a statistical test, but you may choose to support more than two\n",
    "* See the following example, and read the comments in the next cell"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "functional-sierra",
   "metadata": {},
   "source": [
    "**The following empty code block** is here to represent the countless questions, visualizations, and statistical tests \n",
    "that did not make your final report. Data scientist often create a myriad of questions, visualizations \n",
    "and statistical tests that do not make it into the final notebook. This is okay and expected. Remember \n",
    "that shotgun approaches to your data such as using pair plots to look at the relationships of each feature \n",
    "are a great way to explore your data, but they have no place in your final report. \n",
    "**Your final report is about showing and supporting your findings, not showing the work you did to get there!**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "approximate-thong",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "incorrect-mailman",
   "metadata": {},
   "source": [
    "## You may use this as a template for how to ask and answer each question:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overhead-sleep",
   "metadata": {},
   "source": [
    "### 1) Question about the data\n",
    "* Ask a question about the data for which you got a meaningful result\n",
    "* There is no connection can be a meaningful result\n",
    "\n",
    "### 2) Visualization of the data answering the question\n",
    "\n",
    "* Visualizations should be accompanied by take-aways telling the reader exactly what you want them to get from the chart\n",
    "* You can include theses as bullet points under the chart\n",
    "* Use your chart title to provide the main take-away from each visualization\n",
    "* Each visualization should answer one, and only one, of the explore questions\n",
    "\n",
    "### 3) Statistical test\n",
    "* Be sure you are using the correct statistical test for the type of variables you are testing\n",
    "* Be sure that you are not violating any of the assumptions for the statistical test you are choosing\n",
    "* Your notebook should run and produce the results of the test you are using (This may be done through imports)\n",
    "* Include an introduction to the kind of test you are doing\n",
    "* Include the Ho and Ha for the test\n",
    "* Include the alpha you are using\n",
    "* Include the readout of the p-value for the test\n",
    "* Interpret the results of the test in natural language (I reject the null hypothesis is not sufficient)\n",
    "\n",
    "### 4) Answer to the question\n",
    "* Answer the question you posed of the data by referring to the chart and statistical test (if you used one)\n",
    "* If the question relates to drivers, explain why the feature in question would/wouldn't make a good driver"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "iraqi-sellers",
   "metadata": {},
   "source": [
    "## Exploration Summary\n",
    "* After your explore section, before you start modeling, provide a summary of your findings in Explore\n",
    "* Include a summary of your take-aways\n",
    "* Include a summary of the features you examined and weather or not you will be going to Modeling with each feature and why\n",
    "* It is important to note which features will be going into your model so the reader knows what features you are using to model on"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "minus-tulsa",
   "metadata": {},
   "source": [
    "## Modeling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "hydraulic-spectrum",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "* Explain how you will be evaluating your models\n",
    "* Include the evaluation metric you will be using and why you have chosen it\n",
    "* Create a baseline and briefly explain how it was calculated "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ranging-rebecca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# If you use code to generate your baseline run the code and generate the output here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-dream",
   "metadata": {},
   "source": [
    "Printout should read: <br>\n",
    "Baseline: \"number\" \"evaluation metric\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "emotional-purchase",
   "metadata": {},
   "source": [
    "### Best 3 Models\n",
    "* Show the three best model results obtained using your selected features to predict the target variable\n",
    "* Typically students will show the top models they are able to generate for three different model types"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "gentle-capability",
   "metadata": {},
   "source": [
    "## You may use this as a template for how to introduce your models:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "intensive-vietnamese",
   "metadata": {},
   "source": [
    "### Model Type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "colonial-newport",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code that runs the best model in that model type goes here \n",
    "# (This may be imported from a module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "distinguished-abuse",
   "metadata": {},
   "source": [
    "Printout of model code should read: <br>\n",
    "\"Model Type\" <br>\n",
    "\"evaluation metric\" on train: \"evaluation result\" <br>\n",
    "\"evaluation metric\" on validate: \"evaluation result\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "regulated-fellowship",
   "metadata": {},
   "source": [
    "### Test Model\n",
    "* Choose the best model out of the three as you best model and explain why you have chosen it\n",
    "* Explain that you will now run your final model on test data to gauge how it will perform on unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "optical-quilt",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Code that runs the best overall model on test data (this may be imported from a module)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "motivated-recycling",
   "metadata": {},
   "source": [
    "Printout of model code should read: <br>\n",
    "\"Model Type\" <br>\n",
    "\"evaluation metric\" on Test: \"evaluation result\" <br>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bright-evans",
   "metadata": {},
   "source": [
    "### Modeling Wrap \n",
    "* Give a final interpretation of how the models test score compares to the baseline and weather you would recommend this model for production"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tutorial-twelve",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "### Summery\n",
    "* Summarize your findings and answer the questions you brought up in explore \n",
    "* Summarize how drivers discovered lead or did not lead to a successful model \n",
    "\n",
    "### Recommendations\n",
    "* Recommendations are actions the stakeholder should take based on your insights\n",
    "\n",
    "### Next Steps\n",
    "* Next Steps are what you, as a Data Scientist, would do if provided more time to work on the project"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "tender-source",
   "metadata": {},
   "source": [
    "**Where there is code in your report there should also be code comments telling the reader what each code block is doing. This is true for any and all code blocks even if you are using a function to import code from a module.**\n",
    "<br>\n",
    "<br>\n",
    "**Your Notebook should contain adequate markdown that documents your thought process, decision making, and navigation through the pipeline. As a Data Scientist, your job does not end with making data discoveries. It includes effectively communicating those discoveries as well. This means documentation is a critical part of your job.**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "frank-castle",
   "metadata": {},
   "source": [
    "# README\n",
    "\n",
    "Your README should contain all of the following elements:\n",
    "\n",
    "* **Title** Gives the name of your project\n",
    "* **Project Description** Describes what your project is and why it is important \n",
    "* **Project Goal** Clearly states what your project sets out to do and how the information gained can be applied to the real world\n",
    "* **Initial Hypotheses** Initial questions used to focus your project \n",
    "* **Project Plan** Guides the reader through the different stages of the pipeline as they relate to your project\n",
    "* **Data Dictionary** Gives a definition for each of the features used in your report and the units they are measured in, if applicable\n",
    "* **Steps to Reproduce** Gives instructions for reproducing your work. i.e. Running your notebook on someone else's computer."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
