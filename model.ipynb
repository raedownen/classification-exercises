{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c0ade44",
   "metadata": {},
   "source": [
    "##Using the titanic data, in your classification-exercises repository, create a notebook, model.ipynb where you will do the following:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7288e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General DS Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Decision Tree and Model Evaluation Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import acquire\n",
    "import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2031fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire Step\n",
    "df = acquire.get_titanic_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f4b0942",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4753aac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prepare.prep_titanic_data(df)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846416fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for modeling\n",
    "X_train_titanic = train.drop(columns=['survived', 'sex', 'embark_town'])\n",
    "y_train_titanic = train.survived\n",
    "\n",
    "X_validate_titanic = validate.drop(columns=['survived', 'sex', 'embark_town'])\n",
    "y_validate_titanic = validate.survived\n",
    "\n",
    "X_test_titanic = test.drop(columns=['survived', 'sex', 'embark_town'])\n",
    "y_test_titanic = test.survived\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb386fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4ac51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_titanic[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e42b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_titanic.shape, X_validate_titanic.shape, X_test_titanic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd213421",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_titanic.shape, y_validate_titanic.shape, y_test_titanic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97d1d5f",
   "metadata": {},
   "source": [
    "### 1. What is your baseline prediction? What is your baseline accuracy? remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f6575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_titanic[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65671fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_titanic.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f31f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mode is a great baseline\n",
    "baseline_titanic = y_train_titanic.mode()\n",
    "\n",
    "# Produce a boolean array with True representing a match between the baseline prediction and reality\n",
    "matches_baseline_prediction = (y_train_titanic == 0)\n",
    "\n",
    "baseline_accuracy = matches_baseline_prediction.mean()\n",
    "print(f\"Baseline accuracy: {round(baseline_accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016e19e3",
   "metadata": {},
   "source": [
    "### 2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1770f136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the model\n",
    "tree1 = DecisionTreeClassifier(max_depth=3, random_state=123)\n",
    "\n",
    "# Fit the model (on train and only train)\n",
    "tree1.fit(X_train_titanic, y_train_titanic)\n",
    "\n",
    "# Use the model\n",
    "# We'll evaluate the model's performance on train, first\n",
    "y_predictions_titanic = tree1.predict(X_train_titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc231b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 7))\n",
    "plot_tree(tree1, feature_names=X_train_titanic.columns, class_names=['0','1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d37e69",
   "metadata": {},
   "source": [
    "### 3. Evaluate your in-sample results using the model score, confusion matrix, and classification report.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e58aa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(tree1.score(X_train_titanic, y_train_titanic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7abae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(tree1.score(X_train_titanic, y_train_titanic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742cd907",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(tree1, X_train_titanic, y_train_titanic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eea9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train_titanic, y_predictions_titanic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5792c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce the classification report on the actual y values and this model's predicted y values\n",
    "report = classification_report(y_train_titanic, y_predictions_titanic, output_dict=True)\n",
    "print(\"Tree of 1 depth\")\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027eab6b",
   "metadata": {},
   "source": [
    "### 4. Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea1accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_train_titanic, y_predictions_titanic).ravel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378724c0",
   "metadata": {},
   "source": [
    "The label of positive and negative is arbitrary. What is sklearn considering to be the positive case here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20078abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb6c432",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_cases = TN + FP\n",
    "positive_cases = FN + TP\n",
    "print(f\"Negative Cases: {negative_cases}\")\n",
    "print(f\"Positive Cases: {positive_cases}\")\n",
    "print(y_train_titanic.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593ba843",
   "metadata": {},
   "source": [
    "Sklearn is calling survival (1) our positive case\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954d5590",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL = TP + FP + FN + TN\n",
    "\n",
    "accuracy = (TP + TN)/ALL\n",
    "true_positive_rate = sensitivity = recall = power = TP/(TP+FN)\n",
    "false_positive_rate = false_alarm_ratio = fallout = FP/(FP+TN)\n",
    "true_negative_rate = specificity = selectivity = TN/(TN+FP)\n",
    "false_negative_rate = miss_rate = FN/(FN+TP)\n",
    "precision = PPV = TP/(TP+FP)\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "support_pos = TP + FN\n",
    "support_neg = FP + TN\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\", '\\n')\n",
    "print(f\"True Positive Rate/Sensitivity/Recall/Power: {true_positive_rate}\", '\\n')\n",
    "print(f\"False Positive Rate/False Alarm Ratio/Fall-out: {false_positive_rate}\", '\\n')\n",
    "print(f\"True Negative Rate/Specificity/Selectivity: {true_negative_rate}\", '\\n')\n",
    "print(f\"False Negative Rate/Miss Rate: {false_negative_rate}\", '\\n')\n",
    "print(f\"Precision/PPV: {precision}\", '\\n')\n",
    "print(f\"F1 Score: {f1_score}\", '\\n')\n",
    "print(f\"Support (0): {support_neg}\", '\\n')\n",
    "print(f\"Support (1): {support_pos}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ab25df",
   "metadata": {},
   "source": [
    "### 5. Run through steps 2-4 using a different max_depth value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5afbf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get loopy\n",
    "for i in range(1, 21):\n",
    "    # Make the model\n",
    "    tree = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    tree = tree.fit(X_train_titanic, y_train_titanic)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    y_predictions = tree.predict(X_train_titanic)\n",
    "\n",
    "    # Produce the classification report on the actual y values and this model's predicted y values\n",
    "    report = classification_report(y_train_titanic, y_predictions_titanic, output_dict=True)\n",
    "    print(f\"Tree with max depth of {i}\")\n",
    "    print(pd.DataFrame(report))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8544aa",
   "metadata": {},
   "source": [
    "### 6. Which model performs better on your in-sample data?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9414f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max depth of 15+ produces the highest accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff24cab",
   "metadata": {},
   "source": [
    "### 7. Which model performs best on your out-of-sample data, the validate set?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3541189b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's continue getting loopy, so we can compare in-sample to out-of-sample\n",
    "metrics = []\n",
    "\n",
    "for i in range(1, 25):\n",
    "    # Make the model\n",
    "    tree = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    tree = tree.fit(X_train_titanic, y_train_titanic)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = tree.score(X_train_titanic, y_train_titanic)\n",
    "    \n",
    "    out_of_sample_accuracy = tree.score(X_validate_titanic, y_validate_titanic)\n",
    "\n",
    "    output = {\n",
    "        \"max_depth\": i,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "titanic = pd.DataFrame(metrics)\n",
    "titanic[\"difference\"] = titanic.train_accuracy - titanic.validate_accuracy\n",
    "titanic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b1a439",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(titanic.max_depth, titanic.train_accuracy, marker = 'o', label = 'Train')\n",
    "plt.plot(titanic.max_depth, titanic.validate_accuracy, marker = 'o', label = 'Validate')\n",
    "plt.title('Overfitting Occurs at Higher Values for Max Depth')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f71bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[titanic.difference <= 0.10].sort_values(by=['validate_accuracy', 'difference'], ascending = [False,True])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0917a885",
   "metadata": {},
   "source": [
    "### 8. Work through these same exercises using the Telco dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f552a684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire Step\n",
    "telco = acquire.get_telco_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083d1a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fe238b",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e007e2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prepare.prep_telco_data(telco)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95ef6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for modeling\n",
    "\n",
    "#functions can't take strings so i dropped all columns that are strings\n",
    "drop_columns = list(train.select_dtypes(include='object').columns) + ['churn_encoded']\n",
    "\n",
    "X_train_telco = train.drop(columns=drop_columns)\n",
    "y_train_telco = train.churn_encoded\n",
    "\n",
    "X_validate_telco = validate.drop(columns=drop_columns)\n",
    "y_validate_telco = validate.churn_encoded\n",
    "\n",
    "X_test_telco = test.drop(columns=drop_columns)\n",
    "y_test_telco = test.churn_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c9921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_telco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a46b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_telco.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5868f909",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_telco.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f688e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_telco.shape, X_validate_telco.shape, X_test_telco.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6656f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_telco.shape, y_validate_telco.shape, y_test_telco.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87365e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_telco[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9907472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_telco.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9331e224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mode is a great baseline\n",
    "baseline = y_train_telco.mode()\n",
    "\n",
    "# Produce a boolean array with True representing a match between the baseline prediction and reality\n",
    "matches_baseline_prediction = (y_train_telco == 0)\n",
    "\n",
    "baseline_accuracy = matches_baseline_prediction.mean()\n",
    "print(f\"Baseline accuracy: {round(baseline_accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff61800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the model\n",
    "tree2 = DecisionTreeClassifier(max_depth=3, random_state=123)\n",
    "\n",
    "# Fit the model (on train and only train)\n",
    "tree2.fit(X_train_telco, y_train_telco)\n",
    "\n",
    "# Use the model\n",
    "# We'll evaluate the model's performance on train, first\n",
    "y_predictions_telco = tree2.predict(X_train_telco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b3bec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 7))\n",
    "plot_tree(tree2, feature_names=X_train_telco.columns, class_names=['0','1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28230910",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(tree2.score(X_train_telco, y_train_telco)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca5c528",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(tree2, X_train_telco, y_train_telco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019be6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train_telco, y_predictions_telco))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af6ed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce the classification report on the actual y values and this model's predicted y values\n",
    "report = classification_report(y_train_telco, y_predictions_telco, output_dict=True)\n",
    "print(\"Tree of 1 depth\")\n",
    "pd.DataFrame(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b301f98a",
   "metadata": {},
   "source": [
    "### Question 4: Just for Fun - Calculate Metrics\n",
    "Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba61dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_train_telco, y_predictions_telco).ravel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a720dd",
   "metadata": {},
   "source": [
    "The label of positive and negative is arbitrary. What is sklearn considering to be the positive case here?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbae911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bbd067",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_cases = TN + FP\n",
    "positive_cases = FN + TP\n",
    "print(f\"Negative Cases: {negative_cases}\")\n",
    "print(f\"Positive Cases: {positive_cases}\")\n",
    "print(y_train_telco.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4620d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL = TP + FP + FN + TN\n",
    "\n",
    "accuracy = (TP + TN)/ALL\n",
    "true_positive_rate = sensitivity = recall = power = TP/(TP+FN)\n",
    "false_positive_rate = false_alarm_ratio = fallout = FP/(FP+TN)\n",
    "true_negative_rate = specificity = selectivity = TN/(TN+FP)\n",
    "false_negative_rate = miss_rate = FN/(FN+TP)\n",
    "precision = PPV = TP/(TP+FP)\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "support_pos = TP + FN\n",
    "support_neg = FP + TN\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\", '\\n')\n",
    "print(f\"True Positive Rate/Sensitivity/Recall/Power: {true_positive_rate}\", '\\n')\n",
    "print(f\"False Positive Rate/False Alarm Ratio/Fall-out: {false_positive_rate}\", '\\n')\n",
    "print(f\"True Negative Rate/Specificity/Selectivity: {true_negative_rate}\", '\\n')\n",
    "print(f\"False Negative Rate/Miss Rate: {false_negative_rate}\", '\\n')\n",
    "print(f\"Precision/PPV: {precision}\", '\\n')\n",
    "print(f\"F1 Score: {f1_score}\", '\\n')\n",
    "print(f\"Support (0): {support_neg}\", '\\n')\n",
    "print(f\"Support (1): {support_pos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5462a7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get loopy\n",
    "for i in range(1, 21):\n",
    "    # Make the model\n",
    "    tree = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    tree = tree.fit(X_train_telco, y_train_telco)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    y_predictions_telco = tree.predict(X_train_telco)\n",
    "\n",
    "    # Produce the classification report on the actual y values and this model's predicted y values\n",
    "    report = classification_report(y_train_telco, y_predictions_telco, output_dict=True)\n",
    "    print(f\"Tree with max depth of {i}\")\n",
    "    print(pd.DataFrame(report))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56dac78",
   "metadata": {},
   "source": [
    "Max depth of 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a340244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's continue getting loopy, so we can compare in-sample to out-of-sample\n",
    "metrics = []\n",
    "\n",
    "for i in range(1, 25):\n",
    "    # Make the model\n",
    "    tree = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    tree = tree.fit(X_train_telco, y_train_telco)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = tree.score(X_train_telco, y_train_telco)\n",
    "    \n",
    "    out_of_sample_accuracy = tree.score(X_validate_telco, y_validate_telco)\n",
    "\n",
    "    output = {\n",
    "        \"max_depth\": i,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "telco = pd.DataFrame(metrics)\n",
    "telco[\"difference\"] = telco.train_accuracy - telco.validate_accuracy\n",
    "telco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a937ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(telco.max_depth, telco.train_accuracy, marker = 'o', label = 'Train')\n",
    "plt.plot(telco.max_depth, telco.validate_accuracy, marker = 'o', label = 'Validate')\n",
    "plt.title('Overfitting Occurs at Higher Values for Max Depth')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e6f431",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco[telco.difference <= 0.10].sort_values(by=['validate_accuracy', 'difference'], ascending = [False,True])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad61770b",
   "metadata": {},
   "source": [
    "### Continue working in your model file with titanic data to do the following:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533da36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033e8e27",
   "metadata": {},
   "source": [
    "### 1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8455c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=1,                  \n",
    "                            max_depth=10, \n",
    "                            random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd59a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train_titanic, y_train_titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bedff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aada2558",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_titanic = rf.predict(X_train_titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc137233",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_titanic = rf.predict_proba(X_train_titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d8ff9a",
   "metadata": {},
   "source": [
    "### 2. Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94d928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train_titanic, y_train_titanic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a278b7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train_titanic, y_pred_titanic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e429afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train_titanic, y_pred_titanic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c574d69",
   "metadata": {},
   "source": [
    "### 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a728c1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_train_titanic, y_predictions_titanic).ravel()\n",
    "\n",
    "ALL = TP + FP + FN + TN\n",
    "\n",
    "TP, TN, FP, FN, ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e40e4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (TP + TN)/ALL\n",
    "true_positive_rate = sensitivity = recall = power = TP/(TP+FN)\n",
    "false_positive_rate = false_alarm_ratio = fallout = FP/(FP+TN)\n",
    "true_negative_rate = specificity = selectivity = TN/(TN+FP)\n",
    "false_negative_rate = miss_rate = FN/(FN+TP)\n",
    "precision = PPV = TP/(TP+FP)\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "support_pos = TP + FN\n",
    "support_neg = FP + TN\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\", '\\n')\n",
    "print(f\"True Positive Rate/Sensitivity/Recall/Power: {true_positive_rate}\", '\\n')\n",
    "print(f\"False Positive Rate/False Alarm Ratio/Fall-out: {false_positive_rate}\", '\\n')\n",
    "print(f\"True Negative Rate/Specificity/Selectivity: {true_negative_rate}\", '\\n')\n",
    "print(f\"False Negative Rate/Miss Rate: {false_negative_rate}\", '\\n')\n",
    "print(f\"Precision/PPV: {precision}\", '\\n')\n",
    "print(f\"F1 Score: {f1_score}\", '\\n')\n",
    "print(f\"Support (0): {support_neg}\", '\\n')\n",
    "print(f\"Support (1): {support_pos}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9011c7e",
   "metadata": {},
   "source": [
    "### 4. Run through steps increasing your min_samples_leaf and decreasing your max_depth.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5bb0e4fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_df = pd.DataFrame(y_train_titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a014908c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prediction = y_train_df.copy()\n",
    "\n",
    "# Let's get loopy\n",
    "# Make the model\n",
    "for i in range(1, 6):\n",
    "    for j in range(10, 5, -1):\n",
    "        rf = RandomForestClassifier(\n",
    "            min_samples_leaf=i, \n",
    "            max_depth=j, \n",
    "            random_state=123\n",
    "        )\n",
    "        rf.fit(X_train_titanic, y_train_titanic)\n",
    "        \n",
    "        curr_preds = rf.predict(X_train_titanic)\n",
    "        \n",
    "        model_prediction[f'msl_{i}_md_{j}'] = curr_preds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e206b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64d78e0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prediction.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162b3819",
   "metadata": {},
   "source": [
    "### 5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f3a999",
   "metadata": {},
   "source": [
    "After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdad8a76",
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals = model_prediction.survived\n",
    "preds = model_prediction.drop(columns = 'survived')\n",
    "\n",
    "for column in preds.columns:\n",
    "    \n",
    "    accuracy = (actuals == preds[column]).mean()\n",
    "    \n",
    "    print(f'{column} accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b33a9b5",
   "metadata": {},
   "source": [
    "# KNN\n",
    "### Continue working in your model file with the titanic dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d980426",
   "metadata": {},
   "outputs": [],
   "source": [
    "import acquire\n",
    "import prepare\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sklearn modules\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "# Data acquisition\n",
    "from pydataset import data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "427bc80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire Step\n",
    "df = acquire.get_titanic_data()\n",
    "#df = df.drop(columns='passenger_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d224fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb262793",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prepare.prep_titanic_data(df)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5640de1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c282d2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for modeling\n",
    "X_train_titanic = train.drop(columns=['survived', 'sex', 'embark_town'])\n",
    "y_train_titanic = train.survived\n",
    "\n",
    "X_validate_titanic = validate.drop(columns=['survived', 'sex', 'embark_town'])\n",
    "y_validate_titanic = validate.survived\n",
    "\n",
    "X_test_titanic = test.drop(columns=['survived', 'sex', 'embark_town'])\n",
    "y_test_titanic = test.survived\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "366579b8",
   "metadata": {},
   "source": [
    "#### 1. Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53f0810b",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_titanic = KNeighborsClassifier(n_neighbors=5, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3d2f2ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_titanic.fit(X_train_titanic, y_train_titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31344fde",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_titanic = knn_titanic.predict(X_train_titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8db5e6d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_titanic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbf4b39a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_titanic = knn_titanic.predict_proba(X_train_titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c242011",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_titanic"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2017496b",
   "metadata": {},
   "source": [
    "\n",
    "#### 2. Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8b87ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn_titanic.score(X_train_titanic, y_train_titanic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75e2a3ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train_titanic, y_pred_titanic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee2c6628",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train_titanic, y_pred_titanic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa0d1fcf",
   "metadata": {},
   "source": [
    "#### 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44e7cbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_train_titanic, y_pred_titanic).ravel()\n",
    "ALL = TP + FP + FN + TN\n",
    "\n",
    "TP, TN, FP, FN, ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26b95c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1afb3b3b",
   "metadata": {},
   "source": [
    "#### 4. Run through steps 1-3 setting k to 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dce4405a",
   "metadata": {},
   "source": [
    "#### 1. CREATE & FIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d48690ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_titanic2 = KNeighborsClassifier(n_neighbors=10, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce729d34",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_titanic2.fit(X_train_titanic, y_train_titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57632e76",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_titanic = knn_titanic2.predict(X_train_titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "087129b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_titanic = knn_titanic2.predict_proba(X_train_titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0d9c3cd",
   "metadata": {},
   "source": [
    "\n",
    "#### 2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e0ee7b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn_titanic2.score(X_train_titanic, y_train_titanic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c021aac5",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train_titanic, y_pred_titanic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bbbd9732",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train_titanic, y_pred_titanic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eefbbc90",
   "metadata": {},
   "source": [
    "#### 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee683ed4",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_train_titanic, y_pred_titanic).ravel()\n",
    "ALL = TP + FP + FN + TN\n",
    "\n",
    "TP, TN, FP, FN, ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f4c253",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ff2bec5",
   "metadata": {},
   "source": [
    "#### 5. Run through steps 1-3 setting k to 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "048a5470",
   "metadata": {},
   "source": [
    "### CREATE & FIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd0549e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_titanic3 = KNeighborsClassifier(n_neighbors=20, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f20defee",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_titanic3.fit(X_train_titanic, y_train_titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc13fbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_titanic = knn_titanic3.predict(X_train_titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb86d556",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba_titanic = knn_titanic3.predict_proba(X_train_titanic)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "710e72fa",
   "metadata": {},
   "source": [
    "#### 2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "564e6585",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn_titanic3.score(X_train_titanic, y_train_titanic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebc896a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train_titanic, y_pred_titanic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a187090f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train_titanic, y_pred_titanic))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4192078",
   "metadata": {},
   "source": [
    "#### 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cf967bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_train_titanic, y_pred_titanic).ravel()\n",
    "ALL = TP + FP + FN + TN\n",
    "\n",
    "TP, TN, FP, FN, ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636f4a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93aacd7e",
   "metadata": {},
   "source": [
    "#### 6. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f46d662",
   "metadata": {},
   "source": [
    "K5 = Accuracy of KNN classifier on training set: 0.80"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0542692",
   "metadata": {},
   "source": [
    "K10 = Accuracy of KNN classifier on training set: 0.74\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "662b5ec8",
   "metadata": {},
   "source": [
    "K20 = Accuracy of KNN classifier on training set: 0.72"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74cc0c1c",
   "metadata": {},
   "source": [
    "K5 performs better."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d27bb8d4",
   "metadata": {},
   "source": [
    "#### 7. Which model performs best on our out-of-sample data from validate?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "464d889a",
   "metadata": {},
   "source": [
    "K5 = Accuracy: 0.7951807228915663"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07134f10",
   "metadata": {},
   "source": [
    "K10 = Accuracy: 0.7449799196787149\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d70ff7",
   "metadata": {},
   "source": [
    "K20 = Accuracy: 0.7188755020080321\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cade8c0a",
   "metadata": {},
   "source": [
    "K5's accuracy was higher that 10 and 20."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01dcc784",
   "metadata": {},
   "source": [
    "# Logistical Regression\n",
    "In these exercises, we'll continue working with the titanic dataset and building logistic regression models. Throughout this exercise, be sure you are training, evaluation, and comparing models on the train and validate datasets. The test dataset should only be used for your final model.  For all of the models you create, choose a threshold that optimizes for accuracy.\n",
    "\n",
    "Do your work for these exercises in either a notebook or a python script named model within your classification-exercises repository. Add, commit, and push your work."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bd228e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "import prepare\n",
    "import acquire\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "083ac2da",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic = acquire.get_titanic_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0054c642",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  \n",
       "0        S  Third  NaN  Southampton      0  \n",
       "1        C  First    C    Cherbourg      0  \n",
       "2        S  Third  NaN  Southampton      1  \n",
       "3        S  First    C  Southampton      0  \n",
       "4        S  Third  NaN  Southampton      1  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41effde5",
   "metadata": {},
   "source": [
    "### 2. Include sex in your model as well. Note that you'll need to encode or create a dummy variable of this feature before including it in a model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1a41679f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   sex_male\n",
       "0         1\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         1"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sex_df = pd.get_dummies(titanic[['sex',]], dummy_na=False, drop_first=[True, True])\n",
    "sex_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ad716df9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>passenger_id</th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   passenger_id  survived  pclass     sex   age  sibsp  parch     fare  \\\n",
       "0             0         0       3    male  22.0      1      0   7.2500   \n",
       "1             1         1       1  female  38.0      1      0  71.2833   \n",
       "2             2         1       3  female  26.0      0      0   7.9250   \n",
       "3             3         1       1  female  35.0      1      0  53.1000   \n",
       "4             4         0       3    male  35.0      0      0   8.0500   \n",
       "\n",
       "  embarked  class deck  embark_town  alone  sex_male  \n",
       "0        S  Third  NaN  Southampton      0         1  \n",
       "1        C  First    C    Cherbourg      0         0  \n",
       "2        S  Third  NaN  Southampton      1         0  \n",
       "3        S  First    C  Southampton      0         0  \n",
       "4        S  Third  NaN  Southampton      1         1  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "titanic1 = pd.concat([titanic, sex_df], axis=1)\n",
    "titanic1.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1298630f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prepare.prep_titanic_data(titanic1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "12ea32c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((498, 13), (214, 13), (179, 13))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, validate.shape, test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d1c78ff1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>male</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>female</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>29.678105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110.8833</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     survived  pclass     sex        age  sibsp  parch      fare  embark_town  \\\n",
       "583         0       1    male  36.000000      0      0   40.1250    Cherbourg   \n",
       "165         1       3    male   9.000000      0      2   20.5250  Southampton   \n",
       "50          0       3    male   7.000000      4      1   39.6875  Southampton   \n",
       "259         1       2  female  50.000000      0      1   26.0000  Southampton   \n",
       "306         1       1  female  29.678105      0      0  110.8833    Cherbourg   \n",
       "\n",
       "     alone  sex_male  sex_male  embark_town_Queenstown  \\\n",
       "583      1         1         1                       0   \n",
       "165      0         1         1                       0   \n",
       "50       0         1         1                       0   \n",
       "259      0         0         0                       0   \n",
       "306      1         0         0                       0   \n",
       "\n",
       "     embark_town_Southampton  \n",
       "583                        0  \n",
       "165                        1  \n",
       "50                         1  \n",
       "259                        1  \n",
       "306                        0  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "afd884ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make new dataframes\n",
    "X_train = train.drop(columns=['survived', 'sex', 'embark_town'])\n",
    "y_train = train.survived\n",
    "\n",
    "X_validate = validate.drop(columns=['survived', 'sex', 'embark_town'])\n",
    "y_validate = validate.survived\n",
    "\n",
    "X_test = test.drop(columns=['survived', 'sex', 'embark_town'])\n",
    "y_test = test.survived"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d93c4e03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pclass</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>alone</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>sex_male</th>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <th>embark_town_Southampton</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>583</th>\n",
       "      <td>1</td>\n",
       "      <td>36.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>40.1250</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165</th>\n",
       "      <td>3</td>\n",
       "      <td>9.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>20.5250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>3</td>\n",
       "      <td>7.000000</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>39.6875</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>259</th>\n",
       "      <td>2</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0000</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>1</td>\n",
       "      <td>29.678105</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>110.8833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pclass        age  sibsp  parch      fare  alone  sex_male  sex_male  \\\n",
       "583       1  36.000000      0      0   40.1250      1         1         1   \n",
       "165       3   9.000000      0      2   20.5250      0         1         1   \n",
       "50        3   7.000000      4      1   39.6875      0         1         1   \n",
       "259       2  50.000000      0      1   26.0000      0         0         0   \n",
       "306       1  29.678105      0      0  110.8833      1         0         0   \n",
       "\n",
       "     embark_town_Queenstown  embark_town_Southampton  \n",
       "583                       0                        0  \n",
       "165                       0                        1  \n",
       "50                        0                        1  \n",
       "259                       0                        1  \n",
       "306                       0                        0  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e5b0b35",
   "metadata": {},
   "source": [
    "# Model 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e32cea",
   "metadata": {},
   "source": [
    "### 1. Create a model that includes age in addition to fare and pclass. Does this model perform better than your baseline?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a69450d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the logistic regression model\n",
    "logit = LogisticRegression(C=1, random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "73ff7038",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, random_state=123)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#  fit the model on train data\n",
    "logit.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "607c322e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# now use the model to make predictions\n",
    "y_pred = logit.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6e6bea20",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 1, 0,\n",
       "       1, 1, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "       0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 1, 1, 0,\n",
       "       0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 1, 0,\n",
       "       1, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 1, 1, 0, 0,\n",
       "       0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 1, 0,\n",
       "       1, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0,\n",
       "       1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0,\n",
       "       0, 1, 1, 1, 1, 0, 1, 0, 1, 0, 1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0,\n",
       "       1, 1, 1, 1, 1, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       1, 0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 1, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0,\n",
       "       1, 0, 1, 1, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#take a look at predictions\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adbcdff5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.6035116 , 0.3964884 ],\n",
       "       [0.8038497 , 0.1961503 ],\n",
       "       [0.96296676, 0.03703324],\n",
       "       [0.21620824, 0.78379176],\n",
       "       [0.0686917 , 0.9313083 ],\n",
       "       [0.79022407, 0.20977593],\n",
       "       [0.85980863, 0.14019137],\n",
       "       [0.76397086, 0.23602914],\n",
       "       [0.84382449, 0.15617551],\n",
       "       [0.97187331, 0.02812669]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# look at predicted probabilites for first 10 observations\n",
    "logit.predict_proba(X_train)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d46e238b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.classes_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "16f2e2a9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dead</th>\n",
       "      <th>survived</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.604</td>\n",
       "      <td>0.396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.804</td>\n",
       "      <td>0.196</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.963</td>\n",
       "      <td>0.037</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.216</td>\n",
       "      <td>0.784</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.069</td>\n",
       "      <td>0.931</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    dead  survived\n",
       "0  0.604     0.396\n",
       "1  0.804     0.196\n",
       "2  0.963     0.037\n",
       "3  0.216     0.784\n",
       "4  0.069     0.931"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# View raw probabilities (output from the model)\n",
    "\n",
    "y_pred_proba = logit.predict_proba(X_train)\n",
    "y_pred_proba = pd.DataFrame(y_pred_proba, columns = ['dead', 'survived'])\n",
    "y_pred_proba.head().round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "413bfb7f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.85       307\n",
      "           1       0.77      0.73      0.75       191\n",
      "\n",
      "    accuracy                           0.81       498\n",
      "   macro avg       0.80      0.80      0.80       498\n",
      "weighted avg       0.81      0.81      0.81       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# classification report\n",
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2b87de3",
   "metadata": {},
   "source": [
    "# Model 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89b182c1",
   "metadata": {},
   "source": [
    "### 3. Try out other combinations of features and models.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "24fbdb7f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change hyperparameter C = 0.01\n",
    "\n",
    "logit2 = LogisticRegression(C=.01 ,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "6eadb504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.01, random_state=123)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "logit2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae9ef6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction\n",
    "y_pred2 = logit2.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6162a6ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.73      0.95      0.83       307\n",
      "           1       0.84      0.45      0.59       191\n",
      "\n",
      "    accuracy                           0.76       498\n",
      "   macro avg       0.79      0.70      0.71       498\n",
      "weighted avg       0.78      0.76      0.74       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "print(classification_report(y_train, y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f4dfe77",
   "metadata": {},
   "source": [
    "# Model 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df9700ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Change hyperparameter C = 10\n",
    "\n",
    "logit3 = LogisticRegression(C=10 ,random_state=123)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8fb8d25b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=10, random_state=123)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# fit the model\n",
    "logit3.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "cfd1de60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# make prediction\n",
    "y_pred3 = logit3.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7024d1a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.84      0.87      0.85       307\n",
      "           1       0.78      0.73      0.75       191\n",
      "\n",
      "    accuracy                           0.82       498\n",
      "   macro avg       0.81      0.80      0.80       498\n",
      "weighted avg       0.82      0.82      0.82       498\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#classification report\n",
    "print(classification_report(y_train, y_pred3))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9941c11f",
   "metadata": {},
   "source": [
    "### 4. Use your best 3 models to predict and evaluate on your validate sample.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "332f6ad4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make prediction for validate dataset\n",
    "\n",
    "y_pred_validate = logit.predict(X_validate)\n",
    "y_pred_validate2 = logit2.predict(X_validate)\n",
    "y_pred_validate3 = logit3.predict(X_validate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "40e55581",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 1: solver = lbfgs, c = 1\n",
      "Accuracy: 0.78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       132\n",
      "           1       0.73      0.67      0.70        82\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.77      0.76      0.76       214\n",
      "weighted avg       0.78      0.78      0.78       214\n",
      "\n",
      "--------------------------------------------------\n",
      "Model 2: solver = lbfgs, c = .01\n",
      "Accuracy: 0.77\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.74      0.98      0.84       132\n",
      "           1       0.92      0.44      0.60        82\n",
      "\n",
      "    accuracy                           0.77       214\n",
      "   macro avg       0.83      0.71      0.72       214\n",
      "weighted avg       0.81      0.77      0.75       214\n",
      "\n",
      "--------------------------------------------------\n",
      "Model 3: solver = lbfgs, c = 10\n",
      "Accuracy: 0.78\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.81      0.85      0.83       132\n",
      "           1       0.73      0.67      0.70        82\n",
      "\n",
      "    accuracy                           0.78       214\n",
      "   macro avg       0.77      0.76      0.76       214\n",
      "weighted avg       0.78      0.78      0.78       214\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Model 1: solver = lbfgs, c = 1\")\n",
    "\n",
    "print('Accuracy: {:.2f}'.format(logit.score(X_validate, y_validate)))\n",
    "\n",
    "print(classification_report(y_validate, y_pred_validate))\n",
    "\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "print(\"Model 2: solver = lbfgs, c = .01\")\n",
    "\n",
    "print('Accuracy: {:.2f}'.format(logit2.score(X_validate, y_validate)))\n",
    "\n",
    "print(classification_report(y_validate, y_pred_validate2))\n",
    "\n",
    "print('--------------------------------------------------')\n",
    "\n",
    "print(\"Model 3: solver = lbfgs, c = 10\")\n",
    "\n",
    "print('Accuracy: {:.2f}'.format(logit3.score(X_validate, y_validate)))\n",
    "\n",
    "print(classification_report(y_validate, y_pred_validate3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "93c26073",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [-1.27781676e+00 -3.88242068e-02 -5.16720206e-01 -1.61804156e-01\n",
      " -1.05641400e-03 -6.38398915e-01 -1.42819396e+00 -1.42819396e+00\n",
      "  1.00914392e+00  1.81470939e-01]\n"
     ]
    }
   ],
   "source": [
    "# look at model 1 coefficents\n",
    " \n",
    "print('Coefficient: \\n', logit.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "4bc0916f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [-0.27865064 -0.01708698 -0.1407132   0.02205654  0.00721229 -0.09367271\n",
      " -0.39987487 -0.39987487  0.03362353 -0.06559861]\n"
     ]
    }
   ],
   "source": [
    "# look at model 2 coefficents\n",
    " \n",
    "print('Coefficient: \\n', logit2.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c532a1a5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Coefficient: \n",
      " [-1.27974769e+00 -3.86987784e-02 -5.59861798e-01 -1.68002039e-01\n",
      " -8.28000876e-04 -6.63280599e-01 -1.44930861e+00 -1.44930861e+00\n",
      "  1.17059379e+00  2.29787999e-01]\n"
     ]
    }
   ],
   "source": [
    "# look at model 3 coefficents\n",
    " \n",
    "print('Coefficient: \\n', logit3.coef_[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "727b8e36",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coeffs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sex_male</th>\n",
       "      <td>-1.428194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex_male</th>\n",
       "      <td>-1.428194</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pclass</th>\n",
       "      <td>-1.277817</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alone</th>\n",
       "      <td>-0.638399</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sibsp</th>\n",
       "      <td>-0.516720</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parch</th>\n",
       "      <td>-0.161804</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-0.038824</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fare</th>\n",
       "      <td>-0.001056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embark_town_Southampton</th>\n",
       "      <td>0.181471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <td>1.009144</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           coeffs\n",
       "sex_male                -1.428194\n",
       "sex_male                -1.428194\n",
       "pclass                  -1.277817\n",
       "alone                   -0.638399\n",
       "sibsp                   -0.516720\n",
       "parch                   -0.161804\n",
       "age                     -0.038824\n",
       "fare                    -0.001056\n",
       "embark_town_Southampton  0.181471\n",
       "embark_town_Queenstown   1.009144"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a dataframe of coefficients and feature names\n",
    "\n",
    "log_coeffs = pd.DataFrame(logit.coef_[0], index = X_train.columns,\n",
    "                          columns = ['coeffs']).sort_values(by = 'coeffs', ascending = True)\n",
    "log_coeffs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c0919952",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coeffs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sex_male</th>\n",
       "      <td>-0.399875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex_male</th>\n",
       "      <td>-0.399875</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pclass</th>\n",
       "      <td>-0.278651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sibsp</th>\n",
       "      <td>-0.140713</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alone</th>\n",
       "      <td>-0.093673</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embark_town_Southampton</th>\n",
       "      <td>-0.065599</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-0.017087</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fare</th>\n",
       "      <td>0.007212</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parch</th>\n",
       "      <td>0.022057</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <td>0.033624</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           coeffs\n",
       "sex_male                -0.399875\n",
       "sex_male                -0.399875\n",
       "pclass                  -0.278651\n",
       "sibsp                   -0.140713\n",
       "alone                   -0.093673\n",
       "embark_town_Southampton -0.065599\n",
       "age                     -0.017087\n",
       "fare                     0.007212\n",
       "parch                    0.022057\n",
       "embark_town_Queenstown   0.033624"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a dataframe of coefficients and feature names\n",
    "\n",
    "log_coeffs2 = pd.DataFrame(logit2.coef_[0], index = X_train.columns,\n",
    "                          columns = ['coeffs']).sort_values(by = 'coeffs', ascending = True)\n",
    "log_coeffs2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3b16477d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>coeffs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>sex_male</th>\n",
       "      <td>-1.449309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sex_male</th>\n",
       "      <td>-1.449309</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pclass</th>\n",
       "      <td>-1.279748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alone</th>\n",
       "      <td>-0.663281</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sibsp</th>\n",
       "      <td>-0.559862</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>parch</th>\n",
       "      <td>-0.168002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>age</th>\n",
       "      <td>-0.038699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fare</th>\n",
       "      <td>-0.000828</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embark_town_Southampton</th>\n",
       "      <td>0.229788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>embark_town_Queenstown</th>\n",
       "      <td>1.170594</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           coeffs\n",
       "sex_male                -1.449309\n",
       "sex_male                -1.449309\n",
       "pclass                  -1.279748\n",
       "alone                   -0.663281\n",
       "sibsp                   -0.559862\n",
       "parch                   -0.168002\n",
       "age                     -0.038699\n",
       "fare                    -0.000828\n",
       "embark_town_Southampton  0.229788\n",
       "embark_town_Queenstown   1.170594"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Make a dataframe of coefficients and feature names\n",
    "\n",
    "log_coeffs3 = pd.DataFrame(logit3.coef_[0], index = X_train.columns,\n",
    "                          columns = ['coeffs']).sort_values(by = 'coeffs', ascending = True)\n",
    "log_coeffs3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d536bc4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39576059",
   "metadata": {},
   "source": [
    "### 5. Choose you best model from the validation performation, and evaluate it on the test dataset. How do the performance metrics compare to validate? to train?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1395b103",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "865dac08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "89ed2c99",
   "metadata": {},
   "source": [
    "Bonus1 How do different strategies for handling the missing values in the age column affect model performance?\n",
    "\n",
    "Bonus2: How do different strategies for encoding sex affect model performance?\n",
    "\n",
    "Bonus3: scikit-learn's LogisticRegression classifier is actually applying a regularization penalty to the coefficients by default. This penalty causes the magnitude of the coefficients in the resulting model to be smaller than they otherwise would be. This value can be modified with the C hyper parameter. Small values of C correspond to a larger penalty, and large values of C correspond to a smaller penalty.\n",
    "Try out the following values for C and note how the coefficients and the model's performance on both the dataset it was trained on and on the validate split are affected.\n",
    "\n",
    "C = .01, .1, 1, 10, 100, 100\n",
    "\n",
    "Bonus Bonus: how does scaling the data interact with your choice of C?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
