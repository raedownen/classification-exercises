{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8c0ade44",
   "metadata": {},
   "source": [
    "##Using the titanic data, in your classification-exercises repository, create a notebook, model.ipynb where you will do the following:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b7288e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "# General DS Imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "# Decision Tree and Model Evaluation Imports\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier, plot_tree, export_text\n",
    "from sklearn.metrics import classification_report, confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import acquire\n",
    "import prepare"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e2031fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire Step\n",
    "df = acquire.get_titanic_data()\n",
    "df = df.drop(columns='passenger_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6f4b0942",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>survived</th>\n",
       "      <th>pclass</th>\n",
       "      <th>sex</th>\n",
       "      <th>age</th>\n",
       "      <th>sibsp</th>\n",
       "      <th>parch</th>\n",
       "      <th>fare</th>\n",
       "      <th>embarked</th>\n",
       "      <th>class</th>\n",
       "      <th>deck</th>\n",
       "      <th>embark_town</th>\n",
       "      <th>alone</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Cherbourg</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>S</td>\n",
       "      <td>First</td>\n",
       "      <td>C</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>S</td>\n",
       "      <td>Third</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Southampton</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   survived  pclass     sex   age  sibsp  parch     fare embarked  class deck  \\\n",
       "0         0       3    male  22.0      1      0   7.2500        S  Third  NaN   \n",
       "1         1       1  female  38.0      1      0  71.2833        C  First    C   \n",
       "2         1       3  female  26.0      0      0   7.9250        S  Third  NaN   \n",
       "3         1       1  female  35.0      1      0  53.1000        S  First    C   \n",
       "4         0       3    male  35.0      0      0   8.0500        S  Third  NaN   \n",
       "\n",
       "   embark_town  alone  \n",
       "0  Southampton      0  \n",
       "1    Cherbourg      0  \n",
       "2  Southampton      1  \n",
       "3  Southampton      0  \n",
       "4  Southampton      1  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "4753aac7",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"['passenger_id'] not found in axis\"",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Input \u001b[0;32mIn [9]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m train, validate, test \u001b[38;5;241m=\u001b[39m \u001b[43mprepare\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprep_titanic_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m train\u001b[38;5;241m.\u001b[39mhead()\n",
      "File \u001b[0;32m~/codeup-data-science/classification-exercises/prepare.py:134\u001b[0m, in \u001b[0;36mprep_titanic_data\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m    130\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprep_titanic_data\u001b[39m(df):\n\u001b[1;32m    131\u001b[0m     \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m    132\u001b[0m \u001b[38;5;124;03m    Combines the clean_titanic_data, split_titanic_data, and impute_mean_age functions.\u001b[39;00m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[0;32m--> 134\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[43mclean_titanic_data\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m     train, validate, test \u001b[38;5;241m=\u001b[39m split_titanic_data(df)\n\u001b[1;32m    138\u001b[0m     train, validate, test \u001b[38;5;241m=\u001b[39m impute_mean_age(train, validate, test)\n",
      "File \u001b[0;32m~/codeup-data-science/classification-exercises/prepare.py:76\u001b[0m, in \u001b[0;36mclean_titanic_data\u001b[0;34m(df)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;66;03m# Drops columns that are already represented by other columns\u001b[39;00m\n\u001b[1;32m     75\u001b[0m cols_to_drop \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mdeck\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124membarked\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpassenger_id\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[0;32m---> 76\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcols_to_drop\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     78\u001b[0m \u001b[38;5;66;03m# Fills the small number of null values for embark_town with the mode\u001b[39;00m\n\u001b[1;32m     79\u001b[0m df[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124membark_town\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m df\u001b[38;5;241m.\u001b[39membark_town\u001b[38;5;241m.\u001b[39mfillna(value\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSouthampton\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/core/frame.py:4954\u001b[0m, in \u001b[0;36mDataFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4806\u001b[0m \u001b[38;5;129m@deprecate_nonkeyword_arguments\u001b[39m(version\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m, allowed_args\u001b[38;5;241m=\u001b[39m[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mself\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlabels\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[1;32m   4807\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdrop\u001b[39m(\n\u001b[1;32m   4808\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4815\u001b[0m     errors: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraise\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   4816\u001b[0m ):\n\u001b[1;32m   4817\u001b[0m     \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   4818\u001b[0m \u001b[38;5;124;03m    Drop specified labels from rows or columns.\u001b[39;00m\n\u001b[1;32m   4819\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   4952\u001b[0m \u001b[38;5;124;03m            weight  1.0     0.8\u001b[39;00m\n\u001b[1;32m   4953\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 4954\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   4955\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlabels\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4956\u001b[0m \u001b[43m        \u001b[49m\u001b[43maxis\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4957\u001b[0m \u001b[43m        \u001b[49m\u001b[43mindex\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mindex\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4958\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4959\u001b[0m \u001b[43m        \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4960\u001b[0m \u001b[43m        \u001b[49m\u001b[43minplace\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minplace\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4961\u001b[0m \u001b[43m        \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   4962\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:4267\u001b[0m, in \u001b[0;36mNDFrame.drop\u001b[0;34m(self, labels, axis, index, columns, level, inplace, errors)\u001b[0m\n\u001b[1;32m   4265\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m axis, labels \u001b[38;5;129;01min\u001b[39;00m axes\u001b[38;5;241m.\u001b[39mitems():\n\u001b[1;32m   4266\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 4267\u001b[0m         obj \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_drop_axis\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxis\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mlevel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4269\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inplace:\n\u001b[1;32m   4270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_update_inplace(obj)\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/core/generic.py:4311\u001b[0m, in \u001b[0;36mNDFrame._drop_axis\u001b[0;34m(self, labels, axis, level, errors, consolidate, only_slice)\u001b[0m\n\u001b[1;32m   4309\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mdrop(labels, level\u001b[38;5;241m=\u001b[39mlevel, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[1;32m   4310\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 4311\u001b[0m         new_axis \u001b[38;5;241m=\u001b[39m \u001b[43maxis\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdrop\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlabels\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   4312\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m axis\u001b[38;5;241m.\u001b[39mget_indexer(new_axis)\n\u001b[1;32m   4314\u001b[0m \u001b[38;5;66;03m# Case for non-unique axis\u001b[39;00m\n\u001b[1;32m   4315\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[0;32m/opt/homebrew/anaconda3/lib/python3.9/site-packages/pandas/core/indexes/base.py:6644\u001b[0m, in \u001b[0;36mIndex.drop\u001b[0;34m(self, labels, errors)\u001b[0m\n\u001b[1;32m   6642\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mask\u001b[38;5;241m.\u001b[39many():\n\u001b[1;32m   6643\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errors \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m-> 6644\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(labels[mask])\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m not found in axis\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   6645\u001b[0m     indexer \u001b[38;5;241m=\u001b[39m indexer[\u001b[38;5;241m~\u001b[39mmask]\n\u001b[1;32m   6646\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdelete(indexer)\n",
      "\u001b[0;31mKeyError\u001b[0m: \"['passenger_id'] not found in axis\""
     ]
    }
   ],
   "source": [
    "train, validate, test = prepare.prep_titanic_data(df)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846416fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for modeling\n",
    "X_train_titanic = train.drop(columns=['survived', 'sex', 'embark_town'])\n",
    "y_train_titanic = train.survived\n",
    "\n",
    "X_validate_titanic = validate.drop(columns=['survived', 'sex', 'embark_town'])\n",
    "y_validate_titanic = validate.survived\n",
    "\n",
    "X_test_titanic = test.drop(columns=['survived', 'sex', 'embark_town'])\n",
    "y_test_titanic = test.survived\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cb386fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_titanic.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b4ac51a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_titanic[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50e42b64",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_titanic.shape, X_validate_titanic.shape, X_test_titanic.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd213421",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_titanic.shape, y_validate_titanic.shape, y_test_titanic.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97d1d5f",
   "metadata": {},
   "source": [
    "### 1. What is your baseline prediction? What is your baseline accuracy? remember: your baseline prediction for a classification problem is predicting the most prevelant class in the training dataset (the mode). When you make those predictions, what is your accuracy? This is your baseline accuracy.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f6575f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_titanic[0:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65671fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_titanic.value_counts()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f31f97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mode is a great baseline\n",
    "baseline_titanic = y_train_titanic.mode()\n",
    "\n",
    "# Produce a boolean array with True representing a match between the baseline prediction and reality\n",
    "matches_baseline_prediction = (y_train_titanic == 0)\n",
    "\n",
    "baseline_accuracy = matches_baseline_prediction.mean()\n",
    "print(f\"Baseline accuracy: {round(baseline_accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "016e19e3",
   "metadata": {},
   "source": [
    "### 2. Fit the decision tree classifier to your training sample and transform (i.e. make predictions on the training sample)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1770f136",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the model\n",
    "tree1 = DecisionTreeClassifier(max_depth=3, random_state=123)\n",
    "\n",
    "# Fit the model (on train and only train)\n",
    "tree1.fit(X_train_titanic, y_train_titanic)\n",
    "\n",
    "# Use the model\n",
    "# We'll evaluate the model's performance on train, first\n",
    "y_predictions_titanic = tree1.predict(X_train_titanic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc231b2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 7))\n",
    "plot_tree(tree1, feature_names=X_train_titanic.columns, class_names=['0','1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3d37e69",
   "metadata": {},
   "source": [
    "### 3. Evaluate your in-sample results using the model score, confusion matrix, and classification report.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e58aa18",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(tree1.score(X_train_titanic, y_train_titanic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7abae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(tree1.score(X_train_titanic, y_train_titanic)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "742cd907",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(tree1, X_train_titanic, y_train_titanic)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5eea9c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train_titanic, y_predictions_titanic))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a5792c78",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce the classification report on the actual y values and this model's predicted y values\n",
    "report = classification_report(y_train_titanic, y_predictions_titanic, output_dict=True)\n",
    "print(\"Tree of 1 depth\")\n",
    "pd.DataFrame(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027eab6b",
   "metadata": {},
   "source": [
    "### 4. Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eea1accf",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_train_titanic, y_predictions_titanic).ravel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "378724c0",
   "metadata": {},
   "source": [
    "The label of positive and negative is arbitrary. What is sklearn considering to be the positive case here?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20078abf",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcb6c432",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_cases = TN + FP\n",
    "positive_cases = FN + TP\n",
    "print(f\"Negative Cases: {negative_cases}\")\n",
    "print(f\"Positive Cases: {positive_cases}\")\n",
    "print(y_train.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "593ba843",
   "metadata": {},
   "source": [
    "Sklearn is calling survival (1) our positive case\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "954d5590",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL = TP + FP + FN + TN\n",
    "\n",
    "accuracy = (TP + TN)/ALL\n",
    "true_positive_rate = sensitivity = recall = power = TP/(TP+FN)\n",
    "false_positive_rate = false_alarm_ratio = fallout = FP/(FP+TN)\n",
    "true_negative_rate = specificity = selectivity = TN/(TN+FP)\n",
    "false_negative_rate = miss_rate = FN/(FN+TP)\n",
    "precision = PPV = TP/(TP+FP)\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "support_pos = TP + FN\n",
    "support_neg = FP + TN\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\", '\\n')\n",
    "print(f\"True Positive Rate/Sensitivity/Recall/Power: {true_positive_rate}\", '\\n')\n",
    "print(f\"False Positive Rate/False Alarm Ratio/Fall-out: {false_positive_rate}\", '\\n')\n",
    "print(f\"True Negative Rate/Specificity/Selectivity: {true_negative_rate}\", '\\n')\n",
    "print(f\"False Negative Rate/Miss Rate: {false_negative_rate}\", '\\n')\n",
    "print(f\"Precision/PPV: {precision}\", '\\n')\n",
    "print(f\"F1 Score: {f1_score}\", '\\n')\n",
    "print(f\"Support (0): {support_neg}\", '\\n')\n",
    "print(f\"Support (1): {support_pos}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ab25df",
   "metadata": {},
   "source": [
    "### 5. Run through steps 2-4 using a different max_depth value.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5afbf82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get loopy\n",
    "for i in range(1, 21):\n",
    "    # Make the model\n",
    "    tree = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    tree = tree.fit(X_train, y_train)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    y_predictions = tree.predict(X_train)\n",
    "\n",
    "    # Produce the classification report on the actual y values and this model's predicted y values\n",
    "    report = classification_report(y_train, y_predictions, output_dict=True)\n",
    "    print(f\"Tree with max depth of {i}\")\n",
    "    print(pd.DataFrame(report))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8544aa",
   "metadata": {},
   "source": [
    "### 6. Which model performs better on your in-sample data?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f9414f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Max depth of 15+ produces the highest accuracy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff24cab",
   "metadata": {},
   "source": [
    "### 7. Which model performs best on your out-of-sample data, the validate set?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3541189b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's continue getting loopy, so we can compare in-sample to out-of-sample\n",
    "metrics = []\n",
    "\n",
    "for i in range(1, 25):\n",
    "    # Make the model\n",
    "    tree = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    tree = tree.fit(X_train_titanic, y_train_titanic)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = tree.score(X_train_titanic, y_train_titanic)\n",
    "    \n",
    "    out_of_sample_accuracy = tree.score(X_validate_titanic, y_validate_titanic)\n",
    "\n",
    "    output = {\n",
    "        \"max_depth\": i,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "titanic = pd.DataFrame(metrics)\n",
    "titanic[\"difference\"] = titanic.train_accuracy - titanic.validate_accuracy\n",
    "titanic\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6b1a439",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(titanic.max_depth, titanic.train_accuracy, marker = 'o', label = 'Train')\n",
    "plt.plot(titanic.max_depth, titanic.validate_accuracy, marker = 'o', label = 'Validate')\n",
    "plt.title('Overfitting Occurs at Higher Values for Max Depth')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5f71bb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "titanic[titanic.difference <= 0.10].sort_values(by=['validate_accuracy', 'difference'], ascending = [False,True])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0917a885",
   "metadata": {},
   "source": [
    "### 8. Work through these same exercises using the Telco dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f552a684",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire Step\n",
    "telco = acquire.get_telco_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "083d1a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39fe238b",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e007e2e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prepare.prep_telco_data(telco)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e95ef6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for modeling\n",
    "\n",
    "#functions can't take strings so i dropped all columns that are strings\n",
    "drop_columns = list(train.select_dtypes(include='object').columns) + ['churn_encoded']\n",
    "\n",
    "X_train_telco = train.drop(columns=drop_columns)\n",
    "y_train_telco = train.churn_encoded\n",
    "\n",
    "X_validate_telco = validate.drop(columns=drop_columns)\n",
    "y_validate_telco = validate.churn_encoded\n",
    "\n",
    "X_test_telco = test.drop(columns=drop_columns)\n",
    "y_test_telco = test.churn_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08c9921a",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_telco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7a46b10",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_telco.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5868f909",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "X_train_telco.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f688e187",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_telco.shape, X_validate_telco.shape, X_test_telco.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6656f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_telco.shape, y_validate_telco.shape, y_test_telco.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e87365e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_telco[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9907472d",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train_telco.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9331e224",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The mode is a great baseline\n",
    "baseline = y_train_telco.mode()\n",
    "\n",
    "# Produce a boolean array with True representing a match between the baseline prediction and reality\n",
    "matches_baseline_prediction = (y_train_telco == 0)\n",
    "\n",
    "baseline_accuracy = matches_baseline_prediction.mean()\n",
    "print(f\"Baseline accuracy: {round(baseline_accuracy, 2)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ff61800",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make the model\n",
    "tree2 = DecisionTreeClassifier(max_depth=3, random_state=123)\n",
    "\n",
    "# Fit the model (on train and only train)\n",
    "tree2.fit(X_train_telco, y_train_telco)\n",
    "\n",
    "# Use the model\n",
    "# We'll evaluate the model's performance on train, first\n",
    "y_predictions_telco = tree2.predict(X_train_telco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3b3bec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 7))\n",
    "plot_tree(tree2, feature_names=X_train_telco.columns, class_names=['0','1'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28230910",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of Decision Tree classifier on training set: {:.2f}'\n",
    "      .format(tree2.score(X_train_telco, y_train_telco)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca5c528",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(tree2, X_train_telco, y_train_telco)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "019be6d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train_telco, y_predictions_telco))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2af6ed73",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Produce the classification report on the actual y values and this model's predicted y values\n",
    "report = classification_report(y_train_telco, y_predictions_telco, output_dict=True)\n",
    "print(\"Tree of 1 depth\")\n",
    "pd.DataFrame(report)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b301f98a",
   "metadata": {},
   "source": [
    "### Question 4: Just for Fun - Calculate Metrics\n",
    "Compute: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ba61dc8",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_train_telco, y_predictions_telco).ravel()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a720dd",
   "metadata": {},
   "source": [
    "The label of positive and negative is arbitrary. What is sklearn considering to be the positive case here?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbae911f",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6bbd067",
   "metadata": {},
   "outputs": [],
   "source": [
    "negative_cases = TN + FP\n",
    "positive_cases = FN + TP\n",
    "print(f\"Negative Cases: {negative_cases}\")\n",
    "print(f\"Positive Cases: {positive_cases}\")\n",
    "print(y_train_telco.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4620d73",
   "metadata": {},
   "outputs": [],
   "source": [
    "ALL = TP + FP + FN + TN\n",
    "\n",
    "accuracy = (TP + TN)/ALL\n",
    "true_positive_rate = sensitivity = recall = power = TP/(TP+FN)\n",
    "false_positive_rate = false_alarm_ratio = fallout = FP/(FP+TN)\n",
    "true_negative_rate = specificity = selectivity = TN/(TN+FP)\n",
    "false_negative_rate = miss_rate = FN/(FN+TP)\n",
    "precision = PPV = TP/(TP+FP)\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "support_pos = TP + FN\n",
    "support_neg = FP + TN\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\", '\\n')\n",
    "print(f\"True Positive Rate/Sensitivity/Recall/Power: {true_positive_rate}\", '\\n')\n",
    "print(f\"False Positive Rate/False Alarm Ratio/Fall-out: {false_positive_rate}\", '\\n')\n",
    "print(f\"True Negative Rate/Specificity/Selectivity: {true_negative_rate}\", '\\n')\n",
    "print(f\"False Negative Rate/Miss Rate: {false_negative_rate}\", '\\n')\n",
    "print(f\"Precision/PPV: {precision}\", '\\n')\n",
    "print(f\"F1 Score: {f1_score}\", '\\n')\n",
    "print(f\"Support (0): {support_neg}\", '\\n')\n",
    "print(f\"Support (1): {support_pos}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5462a7ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's get loopy\n",
    "for i in range(1, 21):\n",
    "    # Make the model\n",
    "    tree = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    tree = tree.fit(X_train_telco, y_train_telco)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    y_predictions_telco = tree.predict(X_train_telco)\n",
    "\n",
    "    # Produce the classification report on the actual y values and this model's predicted y values\n",
    "    report = classification_report(y_train_telco, y_predictions_telco, output_dict=True)\n",
    "    print(f\"Tree with max depth of {i}\")\n",
    "    print(pd.DataFrame(report))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d56dac78",
   "metadata": {},
   "source": [
    "Max depth of 19"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a340244",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's continue getting loopy, so we can compare in-sample to out-of-sample\n",
    "metrics = []\n",
    "\n",
    "for i in range(1, 25):\n",
    "    # Make the model\n",
    "    tree = DecisionTreeClassifier(max_depth=i, random_state=123)\n",
    "\n",
    "    # Fit the model (on train and only train)\n",
    "    tree = tree.fit(X_train_telco, y_train_telco)\n",
    "\n",
    "    # Use the model\n",
    "    # We'll evaluate the model's performance on train, first\n",
    "    in_sample_accuracy = tree.score(X_train_telco, y_train_telco)\n",
    "    \n",
    "    out_of_sample_accuracy = tree.score(X_validate_telco, y_validate_telco)\n",
    "\n",
    "    output = {\n",
    "        \"max_depth\": i,\n",
    "        \"train_accuracy\": in_sample_accuracy,\n",
    "        \"validate_accuracy\": out_of_sample_accuracy\n",
    "    }\n",
    "    \n",
    "    metrics.append(output)\n",
    "    \n",
    "telco = pd.DataFrame(metrics)\n",
    "telco[\"difference\"] = telco.train_accuracy - telco.validate_accuracy\n",
    "telco"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a937ed9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(telco.max_depth, telco.train_accuracy, marker = 'o', label = 'Train')\n",
    "plt.plot(telco.max_depth, telco.validate_accuracy, marker = 'o', label = 'Validate')\n",
    "plt.title('Overfitting Occurs at Higher Values for Max Depth')\n",
    "plt.xlabel('Max Depth')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e6f431",
   "metadata": {},
   "outputs": [],
   "source": [
    "telco[telco.difference <= 0.10].sort_values(by=['validate_accuracy', 'difference'], ascending = [False,True])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad61770b",
   "metadata": {},
   "source": [
    "### Continue working in your model file with titanic data to do the following:\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "533da36b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "033e8e27",
   "metadata": {},
   "source": [
    "### 1. Fit the Random Forest classifier to your training sample and transform (i.e. make predictions on the training sample) setting the random_state accordingly and setting min_samples_leaf = 1 and max_depth = 10.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff8455c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf = RandomForestClassifier(bootstrap=True, \n",
    "                            class_weight=None, \n",
    "                            criterion='gini',\n",
    "                            min_samples_leaf=1,                  \n",
    "                            max_depth=10, \n",
    "                            random_state=123)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebd59a95",
   "metadata": {},
   "outputs": [],
   "source": [
    "rf.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6bedff1",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aada2558",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = rf.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc137233",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = rf.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77d8ff9a",
   "metadata": {},
   "source": [
    "### 2. Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e94d928c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of random forest classifier on training set: {:.2f}'\n",
    "     .format(rf.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a278b7e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e429afb",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3c574d69",
   "metadata": {},
   "source": [
    "### 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a728c1e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_train, y_predictions).ravel()\n",
    "\n",
    "ALL = TP + FP + FN + TN\n",
    "\n",
    "TP, TN, FP, FN, ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e40e4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (TP + TN)/ALL\n",
    "true_positive_rate = sensitivity = recall = power = TP/(TP+FN)\n",
    "false_positive_rate = false_alarm_ratio = fallout = FP/(FP+TN)\n",
    "true_negative_rate = specificity = selectivity = TN/(TN+FP)\n",
    "false_negative_rate = miss_rate = FN/(FN+TP)\n",
    "precision = PPV = TP/(TP+FP)\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "support_pos = TP + FN\n",
    "support_neg = FP + TN\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\", '\\n')\n",
    "print(f\"True Positive Rate/Sensitivity/Recall/Power: {true_positive_rate}\", '\\n')\n",
    "print(f\"False Positive Rate/False Alarm Ratio/Fall-out: {false_positive_rate}\", '\\n')\n",
    "print(f\"True Negative Rate/Specificity/Selectivity: {true_negative_rate}\", '\\n')\n",
    "print(f\"False Negative Rate/Miss Rate: {false_negative_rate}\", '\\n')\n",
    "print(f\"Precision/PPV: {precision}\", '\\n')\n",
    "print(f\"F1 Score: {f1_score}\", '\\n')\n",
    "print(f\"Support (0): {support_neg}\", '\\n')\n",
    "print(f\"Support (1): {support_pos}\")"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c033eef5",
   "metadata": {},
   "source": [
    "Accuracy = .89\n",
    "TP = 746\n",
    "FP = 141\n",
    "TN = 2750\n",
    "FN = 300\n",
    "Precision = .84\n",
    "Recall = .71\n",
    "F1 = .77\n",
    "Support = 1046"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9011c7e",
   "metadata": {},
   "source": [
    "### 4. Run through steps increasing your min_samples_leaf and decreasing your max_depth.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a014908c",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prediction = y_train.copy()\n",
    "\n",
    "# Let's get loopy\n",
    "# Make the model\n",
    "for i in range(1, 6):\n",
    "    for j in range(10, 5, -1):\n",
    "        rf = RandomForestClassifier(\n",
    "            max_depth=i, \n",
    "            min_samples_leaf=j, \n",
    "            random_state=123\n",
    "        )\n",
    "        rf.fit(X_train, y_train)\n",
    "        \n",
    "        curr_preds = rf.predict(X_train)\n",
    "        \n",
    "        model_prediction[f'msl_{i}_md_{j}'] = curr_preds\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e206b01",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "162b3819",
   "metadata": {},
   "source": [
    "### 5. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02f3a999",
   "metadata": {},
   "source": [
    "After making a few models, which one has the best performance (or closest metrics) on both train and validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a64b139",
   "metadata": {},
   "outputs": [],
   "source": [
    "actuals = model_prediction.survived\n",
    "preds = model_prediction.drop(columns = 'survived')\n",
    "\n",
    "for column in preds.columns:\n",
    "    accuracy = (actuals == pred[column]).mean()\n",
    "    print(f'{column} accuracy: {accuracy}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "139edda9",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad5d37ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c01be304",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df9d1bca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2b9ca631",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08d1a7e9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "011d565e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41f8f5f9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9b4fd5e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16850bb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import acquire\n",
    "import prepare\n",
    "\n",
    "# Ignore warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "# Data handling\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Sklearn modules\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix, plot_confusion_matrix\n",
    "\n",
    "# Data acquisition\n",
    "from pydataset import data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "caa26ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Acquire Step\n",
    "df = acquire.get_titanic_data()\n",
    "#df = df.drop(columns='passenger_id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09a20373",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcc1dd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "train, validate, test = prepare.prep_titanic_data(df)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7bddbafd",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ad7729",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprocessing for modeling\n",
    "X_train_titanic = train.drop(columns=['survived', 'sex', 'embark_town'])\n",
    "y_train_titanic = train.survived\n",
    "\n",
    "X_validate_titanic = validate.drop(columns=['survived', 'sex', 'embark_town'])\n",
    "y_validate_titanic = validate.survived\n",
    "\n",
    "X_test_titanic = test.drop(columns=['survived', 'sex', 'embark_town'])\n",
    "y_test_titanic = test.survived\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "418375ff",
   "metadata": {},
   "source": [
    "# KNN\n",
    "### Continue working in your model file with the titanic dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9837790",
   "metadata": {},
   "source": [
    "#### 1. Fit a K-Nearest Neighbors classifier to your training sample and transform (i.e. make predictions on the training sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a5edcf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_titanic = KNeighborsClassifier(n_neighbors=5, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9da1c505",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_titanic.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca3deab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn_titanic.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e59c3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = knn_titanic.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3eaf938",
   "metadata": {},
   "source": [
    "\n",
    "#### 2. Evaluate your results using the model score, confusion matrix, and classification report.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a25d1d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn_titanic.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f18fc58",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8507c49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4852e217",
   "metadata": {},
   "source": [
    "#### 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfb0981c",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_train, y_pred).ravel()\n",
    "ALL = TP + FP + FN + TN\n",
    "\n",
    "TP, TN, FP, FN, ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3653d125",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8992854f",
   "metadata": {},
   "source": [
    "#### 4. Run through steps 1-3 setting k to 10\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bafb3409",
   "metadata": {},
   "source": [
    "#### 1. CREATE & FIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcc618f5",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_titanic2 = KNeighborsClassifier(n_neighbors=10, weights='uniform')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e38a5f52",
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_titanic2.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89fd2afe",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = knn_titanic2.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b393bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred_proba = knn_titanic2.predict_proba(X_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d401271c",
   "metadata": {},
   "source": [
    "\n",
    "#### 2. Evaluate your results using the model score, confusion matrix, and classification report."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4f4d917",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Accuracy of KNN classifier on training set: {:.2f}'\n",
    "     .format(knn_titanic2.score(X_train, y_train)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f625d0ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(confusion_matrix(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b229660f",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(classification_report(y_train, y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "58cfd532",
   "metadata": {},
   "source": [
    "#### 3. Print and clearly label the following: Accuracy, true positive rate, false positive rate, true negative rate, false negative rate, precision, recall, f1-score, and support."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb81a7cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "TN, FP, FN, TP = confusion_matrix(y_train, y_pred).ravel()\n",
    "ALL = TP + FP + FN + TN\n",
    "\n",
    "TP, TN, FP, FN, ALL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce5c4750",
   "metadata": {},
   "outputs": [],
   "source": [
    "accuracy = (TP + TN)/ALL\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "\n",
    "true_positive_rate = TP/(TP+FN)\n",
    "print(f\"True Positive Rate: {true_positive_rate}\")\n",
    "\n",
    "false_positive_rate = FP/(FP+TN)\n",
    "print(f\"False Positive Rate: {false_positive_rate}\")\n",
    "\n",
    "true_negative_rate = TN/(TN+FP)\n",
    "print(f\"True Negative Rate: {true_negative_rate}\")\n",
    "\n",
    "false_negative_rate = FN/(FN+TP)\n",
    "print(f\"False Negative Rate: {false_negative_rate}\")\n",
    "\n",
    "precision = TP/(TP+FP)\n",
    "print(f\"Precision: {precision}\")\n",
    "\n",
    "recall = TP/(TP+FN)\n",
    "print(f\"Recall: {recall}\")\n",
    "\n",
    "f1_score = 2*(precision*recall)/(precision+recall)\n",
    "print(f\"F1 Score: {f1_score}\")\n",
    "\n",
    "support_pos = TP + FN\n",
    "print(f\"Support (0): {support_pos}\")\n",
    "\n",
    "support_neg = FP + TN\n",
    "print(f\"Support (1): {support_neg}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39a8bce6",
   "metadata": {},
   "source": [
    "#### 5. Run through steps 1-3 setting k to 20\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "087b0030",
   "metadata": {},
   "source": [
    "#### 6. What are the differences in the evaluation metrics? Which performs better on your in-sample data? Why?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2f003eb",
   "metadata": {},
   "source": [
    "#### 7. Which model performs best on our out-of-sample data from validate?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66669908",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
